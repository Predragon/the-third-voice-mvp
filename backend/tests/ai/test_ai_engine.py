"""
Enhanced Test Suite for AI Engine Functionality - Intelligent Contract Testing
"""
import pytest
import asyncio
import sys
from unittest.mock import Mock, AsyncMock, patch, MagicMock
from typing import Optional, List, Dict, Any
import re

# Mock all database-related dependencies before any imports
sys.modules['sqlalchemy'] = MagicMock()
sys.modules['sqlalchemy.orm'] = MagicMock()
sys.modules['sqlalchemy.ext'] = MagicMock()
sys.modules['sqlalchemy.ext.declarative'] = MagicMock()
sys.modules['src.data.database'] = MagicMock()
sys.modules['src.data.crud'] = MagicMock()
sys.modules['src.data.models'] = MagicMock()

# Mock database manager
mock_db_manager = MagicMock()
sys.modules['src.data.database'].db_manager = mock_db_manager
sys.modules['src.data.database'].get_database_manager = lambda: mock_db_manager

# Mock CRUD operations
mock_cache_crud = MagicMock()
mock_cache_crud.get_cached_response = MagicMock(return_value=None)
mock_cache_crud.cache_response = MagicMock()
sys.modules['src.data.crud'].CacheCRUD = mock_cache_crud

# Now we can safely import the AI engine components
try:
    from src.ai.ai_engine import AIEngine, AIResponse, AnalysisDepth
    AI_ENGINE_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ AI Engine not available: {e}")
    AI_ENGINE_AVAILABLE = False
    
    # Create mock classes for testing
    class MockAnalysisDepth:
        QUICK = MagicMock()
        QUICK.value = "quick"
        DEEP = MagicMock()
        DEEP.value = "deep"
    
    class MockAIResponse:
        def __init__(self, **kwargs):
            self.transformed_message = kwargs.get('transformed_message', '')
            self.healing_score = kwargs.get('healing_score', 0)
            self.sentiment = kwargs.get('sentiment', 'neutral')
            self.emotional_state = kwargs.get('emotional_state', 'unknown')
            self.needs = kwargs.get('needs', [])
            self.warnings = kwargs.get('warnings', [])
            self.suggested_responses = kwargs.get('suggested_responses', [])
            self.explanation = kwargs.get('explanation', '')
            self.model_used = kwargs.get('model_used', 'mock')
            self.analysis_depth = kwargs.get('analysis_depth', 'quick')
    
    class MockAIEngine:
        def __init__(self):
            self.models = [
                {"id": "mock/model:free", "name": "Mock Model", "note": "Test model"},
                {"id": "test/model:free", "name": "Test Model", "note": "Another test model"}
            ]
            self.client = MagicMock()
            self._prewarmed = False
        
        def _sanitize_message(self, message: str) -> str:
            replacements = {
                'fucking': '[strong expletive]',
                'bitch': '[expletive]',
                'shit': '[expletive]',
                'damn': '[mild expletive]'
            }
            result = message
            for word, replacement in replacements.items():
                result = result.replace(word, replacement)
            return result
        
        def _get_model_display_name(self, model_id: str) -> str:
            if "deepseek-chat-v3.1" in model_id:
                return "DeepSeek Chat v3.1"
            model_name = model_id.split('/')[-1].split(':')[0]
            return model_name
        
        def _create_message_hash(self, message: str, context: str, msg_type: str, depth: str) -> str:
            import hashlib
            combined = f"{message}{context}{msg_type}{depth}"
            return hashlib.md5(combined.encode()).hexdigest()
        
        def _get_interpret_fallback(self, message: str) -> 'MockAIResponse':
            return MockAIResponse(
                explanation="Fallback analysis",
                healing_score=5,
                sentiment="neutral",
                suggested_responses=["I understand", "Tell me more", "That sounds difficult"],
                model_used="Fallback System"
            )
        
        def _get_transform_fallback(self, message: str) -> 'MockAIResponse':
            return MockAIResponse(
                transformed_message=f"Transformed: {message}",
                model_used="Fallback System"
            )
        
        def _get_quick_analysis_prompts(self, message: str, context: str):
            system_prompt = "You are an AI that provides JSON responses for quick analysis"
            user_prompts = [message, self._sanitize_message(message)]
            return system_prompt, user_prompts
        
        def _get_deep_analysis_prompts(self, message: str, context: str):
            system_prompt = "You are an AI that provides deep psychological analysis"
            user_prompts = [message, self._sanitize_message(message)]
            return system_prompt, user_prompts
        
        def _get_transform_prompts(self, message: str, context: str):
            system_prompt = "You are an AI that helps rewrite messages"
            user_prompts = [message, self._sanitize_message(message)]
            return system_prompt, user_prompts
        
        async def process_message(self, message: str, contact_context: str, message_type: str, 
                                contact_id: str, user_id: str, analysis_depth: str = "quick"):
            # Simulate real AI behavior with varied responses
            return MockAIResponse(
                explanation=f"Analysis of message: {message}",
                healing_score=7,
                sentiment="positive",
                suggested_responses=["response1", "response2", "response3"]
            )
        
        async def quick_analyze(self, message: str, context: str, contact_id: str, user_id: str):
            return await self.process_message(message, context, "interpret", contact_id, user_id, "quick")
        
        async def deep_analyze(self, message: str, context: str, contact_id: str, user_id: str):
            return await self.process_message(message, context, "interpret", contact_id, user_id, "deep")
        
        async def transform(self, message: str, context: str, contact_id: str, user_id: str):
            return await self.process_message(message, context, "transform", contact_id, user_id, "quick")
        
        async def lazy_prewarm(self):
            self._prewarmed = True
        
        async def cleanup(self):
            if hasattr(self.client, 'aclose'):
                await self.client.aclose()
    
    # Use mock classes
    AIEngine = MockAIEngine
    AIResponse = MockAIResponse
    AnalysisDepth = MockAnalysisDepth


# ----------------------------
# Intelligent Test Helpers
# ----------------------------

def validate_explanation_quality(explanation: str, message: str) -> bool:
    """
    Validate that explanation shows understanding of the message content
    without requiring exact string matches.
    """
    if not explanation or len(explanation.strip()) < 10:
        return False
    
    # Check for meaningful analysis keywords
    analysis_indicators = [
        'test', 'message', 'functionality', 'communication', 'helper',
        'user', 'checking', 'verify', 'understand', 'interpret', 'analysis'
    ]
    
    explanation_lower = explanation.lower()
    message_lower = message.lower()
    
    # For test messages, look for test-related analysis
    if 'test' in message_lower:
        test_keywords = ['test', 'functionality', 'verify', 'checking', 'communication']
        return any(keyword in explanation_lower for keyword in test_keywords)
    
    # For emotional messages, look for emotional understanding
    if any(word in message_lower for word in ['upset', 'feeling', 'overwhelmed', 'stressed']):
        emotional_keywords = ['emotional', 'feeling', 'support', 'understanding', 'discomfort', 'stress']
        return any(keyword in explanation_lower for keyword in emotional_keywords)
    
    # General quality check - explanation should be substantive
    return len(explanation.split()) >= 5

def validate_sentiment_appropriateness(sentiment: str, message: str) -> bool:
    """
    Validate that sentiment matches message content appropriately.
    """
    valid_sentiments = ['positive', 'negative', 'neutral', 'mixed', 'anxious', 'stressed', 'happy', 'sad', 'angry', 'confused']
    
    if sentiment not in valid_sentiments:
        return False
    
    message_lower = message.lower()
    
    # Negative emotional indicators should not result in positive sentiment
    negative_indicators = ['upset', 'overwhelmed', 'stressed', 'anxious', 'worried', 'sad', 'angry']
    if any(indicator in message_lower for indicator in negative_indicators):
        return sentiment not in ['positive', 'happy']
    
    # Test messages can be neutral or positive
    if 'test' in message_lower:
        return sentiment in ['neutral', 'positive']
    
    return True

def validate_healing_score_appropriateness(score: int, message: str, sentiment: str) -> bool:
    """
    Validate that healing score is appropriate for message content and sentiment.
    """
    if not (0 <= score <= 10):
        return False
    
    message_lower = message.lower()
    
    # Distressed messages should have lower healing scores
    if any(word in message_lower for word in ['upset', 'overwhelmed', 'stressed', 'anxious']):
        return score <= 7  # Allow some flexibility
    
    # Test messages can have higher scores
    if 'test' in message_lower:
        return score >= 3  # Should be reasonably positive
    
    return True

def validate_suggested_responses_quality(responses: List[str], message: str) -> bool:
    """
    Validate that suggested responses are appropriate and helpful.
    """
    if not responses or len(responses) < 1:
        return False
    
    # Check that responses are non-empty strings
    if not all(isinstance(r, str) and r.strip() for r in responses):
        return False
    
    # Check for supportive/helpful language
    supportive_patterns = [
        r'\b(understand|tell me|sounds|feel|help|support|here|listen)\b',
        r'\b(more|difficult|hard|sorry|care|important)\b'
    ]
    
    responses_text = ' '.join(responses).lower()
    return any(re.search(pattern, responses_text) for pattern in supportive_patterns)


# ----------------------------
# Contract-based tests for AIEngine (Enhanced)
# ----------------------------

@pytest.mark.asyncio
@pytest.mark.parametrize("message", [
    "test message",
    "I'm feeling really overwhelmed with work lately",
    "Hello there!"
])
async def test_process_message_contract(message):
    """Enhanced contract-based test for AIEngine process_message outputs."""
    engine = AIEngine()
    response = await engine.process_message(
        message=message,
        contact_context="test context",
        message_type="interpret",
        contact_id="test_contact",
        user_id="test_user"
    )

    # Must return AIResponse
    assert isinstance(response, AIResponse), "Response must be AIResponse instance"

    # Explanation must be meaningful
    assert isinstance(response.explanation, str), "Explanation must be string"
    assert validate_explanation_quality(response.explanation, message), \
        f"Explanation quality check failed for message '{message}'. Got: '{response.explanation}'"

    # Healing score must be valid and appropriate
    assert isinstance(response.healing_score, int), "Healing score must be integer"
    assert validate_healing_score_appropriateness(response.healing_score, message, response.sentiment), \
        f"Healing score {response.healing_score} inappropriate for message '{message}' with sentiment '{response.sentiment}'"

    # Sentiment must be appropriate
    assert isinstance(response.sentiment, str), "Sentiment must be string"
    assert validate_sentiment_appropriateness(response.sentiment, message), \
        f"Sentiment '{response.sentiment}' inappropriate for message '{message}'"

    # Suggested responses must be helpful
    assert isinstance(response.suggested_responses, list), "Suggested responses must be list"
    assert validate_suggested_responses_quality(response.suggested_responses, message), \
        f"Suggested responses quality check failed for message '{message}'. Got: {response.suggested_responses}"

    # Model used must be identified
    assert isinstance(response.model_used, str), "Model used must be string"
    assert response.model_used.strip() != "", "Model used must not be empty"


# ----------------------------
# Fallback test (flexible)
# ----------------------------

@pytest.mark.asyncio
async def test_process_message_fallback_behavior():
    """Test that fallback behavior provides appropriate responses."""
    engine = AIEngine()
    
    # Test with emotional message that might trigger fallback
    response = await engine.process_message(
        message="I'm feeling upset",
        contact_context="test context",
        message_type="interpret",
        contact_id="test_contact",
        user_id="test_user"
    )

    # Validate contract compliance
    assert isinstance(response, AIResponse)
    assert isinstance(response.explanation, str)
    assert response.explanation.strip() != ""
    assert isinstance(response.healing_score, int)
    assert 0 <= response.healing_score <= 10
    assert isinstance(response.sentiment, str)
    assert response.sentiment.strip() != ""
    assert isinstance(response.suggested_responses, list)
    assert len(response.suggested_responses) > 0
    assert isinstance(response.model_used, str)
    assert response.model_used.strip() != ""
    
    # Validate appropriateness for emotional content
    assert validate_sentiment_appropriateness(response.sentiment, "I'm feeling upset")
    assert validate_healing_score_appropriateness(response.healing_score, "I'm feeling upset", response.sentiment)
    assert validate_suggested_responses_quality(response.suggested_responses, "I'm feeling upset")


# ----------------------------
# Semantic Content Tests
# ----------------------------

@pytest.mark.asyncio
@pytest.mark.parametrize("message,expected_themes", [
    ("test message", ["test", "functionality", "verify", "communication"]),
    ("I'm feeling overwhelmed with work", ["emotional", "stress", "work", "overwhelmed", "support"]),
    ("Hello there!", ["greeting", "social", "friendly", "interaction"])
])
async def test_explanation_semantic_content(message, expected_themes):
    """Test that explanations contain appropriate semantic themes."""
    engine = AIEngine()
    response = await engine.process_message(
        message=message,
        contact_context="test context",
        message_type="interpret",
        contact_id="test_contact",
        user_id="test_user"
    )
    
    explanation_lower = response.explanation.lower()
    
    # At least some expected themes should be present
    themes_found = sum(1 for theme in expected_themes if theme in explanation_lower)
    assert themes_found >= 1, \
        f"Expected themes {expected_themes} not found in explanation: '{response.explanation}'"


# ----------------------------
# Integration Tests
# ----------------------------

@pytest.mark.asyncio
async def test_full_workflow_integration():
    """Test complete workflow from initialization to cleanup."""
    engine = AIEngine()
    
    # Test initialization
    assert engine is not None
    assert hasattr(engine, 'models')
    
    # Test prewarming
    await engine.lazy_prewarm()
    assert engine._prewarmed
    
    # Test message processing
    response = await engine.process_message(
        message="Integration test message",
        contact_context="test context",
        message_type="interpret",
        contact_id="test_contact",
        user_id="test_user"
    )
    
    # Validate response
    assert isinstance(response, AIResponse)
    assert validate_explanation_quality(response.explanation, "Integration test message")
    
    # Test cleanup
    await engine.cleanup()


@pytest.mark.asyncio
async def test_multiple_message_consistency():
    """Test that multiple similar messages produce consistent quality responses."""
    engine = AIEngine()
    
    messages = [
        "I'm having a difficult day",
        "Today has been really challenging",
        "I'm struggling with some personal issues"
    ]
    
    responses = []
    for message in messages:
        response = await engine.process_message(
            message=message,
            contact_context="close friend",
            message_type="interpret",
            contact_id="friend_123",
            user_id="user_456"
        )
        responses.append(response)
    
    # All responses should meet quality standards
    for i, response in enumerate(responses):
        assert validate_explanation_quality(response.explanation, messages[i])
        assert validate_sentiment_appropriateness(response.sentiment, messages[i])
        assert validate_healing_score_appropriateness(response.healing_score, messages[i], response.sentiment)
        assert validate_suggested_responses_quality(response.suggested_responses, messages[i])
    
    # Healing scores should be consistently in appropriate range for emotional content
    healing_scores = [r.healing_score for r in responses]
    assert all(score <= 7 for score in healing_scores), \
        f"Healing scores too high for emotional messages: {healing_scores}"


# ----------------------------
# Original structural tests (unchanged)
# ----------------------------

@pytest.mark.skipif(not AI_ENGINE_AVAILABLE, reason="AI Engine dependencies not available")
def test_ai_engine_import():
    """Test that AI engine can be imported"""
    try:
        from src.ai.ai_engine import AIEngine
        assert True
        print("âœ… AI Engine import successful")
    except ImportError as e:
        pytest.fail(f"AI Engine import failed: {e}")


def test_ai_engine_initialization():
    """Test that AI engine can be initialized"""
    try:
        engine = AIEngine()
        assert engine is not None
        assert hasattr(engine, 'models')
        assert hasattr(engine, 'client')
        assert len(engine.models) > 0
        print("âœ… AI Engine initialization successful")
    except Exception as e:
        pytest.fail(f"AI Engine initialization failed: {e}")


def test_ai_engine_methods():
    """Test that AI engine has required methods"""
    engine = AIEngine()
    
    # Check for core methods
    assert hasattr(engine, 'process_message'), "AIEngine should have process_message method"
    assert hasattr(engine, 'quick_analyze'), "AIEngine should have quick_analyze method"
    assert hasattr(engine, 'deep_analyze'), "AIEngine should have deep_analyze method"
    assert hasattr(engine, 'transform'), "AIEngine should have transform method"
    assert hasattr(engine, 'lazy_prewarm'), "AIEngine should have lazy_prewarm method"
    assert hasattr(engine, 'cleanup'), "AIEngine should have cleanup method"
    
    print("âœ… AI Engine has required methods")


def test_message_sanitization():
    """Test message sanitization functionality"""
    engine = AIEngine()
    
    # Test basic sanitization
    original = "This is fucking bullshit, you bitch!"
    sanitized = engine._sanitize_message(original)
    
    assert "[strong expletive]" in sanitized
    assert "[expletive]" in sanitized
    assert "fucking" not in sanitized
    assert "bitch" not in sanitized
    
    print("âœ… Message sanitization working correctly")


@pytest.mark.asyncio
async def test_shortcut_methods():
    """Test shortcut methods"""
    engine = AIEngine()
    
    # Test quick_analyze
    response = await engine.quick_analyze("test", "context", "contact", "user")
    assert isinstance(response, AIResponse)
    
    # Test deep_analyze
    response = await engine.deep_analyze("test", "context", "contact", "user")
    assert isinstance(response, AIResponse)
    
    # Test transform
    response = await engine.transform("test", "context", "contact", "user")
    assert isinstance(response, AIResponse)
    
    print("âœ… Shortcut methods test passed")


# Integration test helper
def run_integration_tests():
    """Run integration tests that don't require external APIs"""
    print("ðŸ§ª Running AI Engine Integration Tests...")
    
    # Test full initialization cycle
    engine = AIEngine()
    assert engine is not None
    
    # Test all core components exist
    assert hasattr(engine, 'models')
    assert hasattr(engine, 'client')
    assert hasattr(engine, '_prewarmed')
    
    # Test utility methods
    sanitized = engine._sanitize_message("This is a test fucking message")
    assert "fucking" not in sanitized
    
    hash_val = engine._create_message_hash("test", "context", "type", "depth")
    assert len(hash_val) == 32  # MD5 hash length
    
    print("âœ… All integration tests passed!")


if __name__ == "__main__":
    # Run integration tests directly
    run_integration_tests()